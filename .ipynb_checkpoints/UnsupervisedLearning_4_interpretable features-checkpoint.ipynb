{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691fe634",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CHAPTER 4 - Discovering interpretable features\n",
    "# Perform the necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import NMF,  PCA\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import normalize, Normalizer, MaxAbsScaler\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f0558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMF applied to Wikipedia articles\n",
    "articles_df = pd.read_csv('Dados/Wikipedia articles/wikipedia-vectors.csv', sep=',', index_col=0)\n",
    "articles = csr_matrix(articles_df.transpose())\n",
    "titles = list(articles_df.columns)\n",
    "\n",
    "# Create an NMF instance: model\n",
    "model = NMF(n_components=6)\n",
    "\n",
    "# Fit the model to articles\n",
    "model.fit(articles)\n",
    "\n",
    "# Transform the articles: nmf_features\n",
    "nmf_features = model.transform(articles)\n",
    "\n",
    "# Print the NMF features\n",
    "print(nmf_features.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMF features of the Wikipedia articles\n",
    "\n",
    "# Create a pandas DataFrame: df\n",
    "df = pd.DataFrame(nmf_features,index=titles)\n",
    "\n",
    "# Print the row for 'Anne Hathaway'\n",
    "print(df.loc['Anne Hathaway',:])\n",
    "\n",
    "# Print the row for 'Denzel Washington'\n",
    "print(df.loc['Denzel Washington',:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbadeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMF reconstructs samples\n",
    "NMF_Components = np.array([[1,0.5,0],[0.2,0.1,2.1]])\n",
    "featuresValuesSample= np.array([[2,1]])\n",
    "np.dot(featuresValuesSample,NMF_Components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13934452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMF learns topics of documents\n",
    "\n",
    "# Create a DataFrame: components_df\n",
    "f = open('Dados/Wikipedia articles/wikipedia-vocabulary-utf8.txt', 'r')\n",
    "#print(f.read())\n",
    "words = f.read().splitlines()\n",
    "\n",
    "components_df = pd.DataFrame(model.components_, columns=words)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(components_df.shape)\n",
    "\n",
    "# Select row 3: component\n",
    "component = components_df.iloc[3,:]\n",
    "\n",
    "# Print result of nlargest\n",
    "print(component.nlargest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f176dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which articles are similar to 'Cristiano Ronaldo'?\n",
    "\n",
    "# Normalize the NMF features: norm_features\n",
    "norm_features = normalize(nmf_features)\n",
    "\n",
    "# Create a DataFrame: df\n",
    "df = pd.DataFrame(norm_features, index=titles)\n",
    "\n",
    "# Select the row corresponding to 'Cristiano Ronaldo': article\n",
    "article = df.loc['Cristiano Ronaldo']\n",
    "\n",
    "# Compute the dot products: similarities\n",
    "similarities = df.dot(article)\n",
    "\n",
    "# Display those with the largest cosine similarity\n",
    "print(similarities.nlargest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the LED digits dataset\n",
    "lcd_df = pd.read_csv('Dados/lcd-digits.csv', sep=',',header = None)\n",
    "lcd_df_samples =  lcd_df.to_numpy()\n",
    "# Select the 0th row: digit\n",
    "digit = lcd_df_samples[0,:]\n",
    "\n",
    "# Print digit\n",
    "print(digit)\n",
    "\n",
    "# Reshape digit to a 13x8 array: bitmap\n",
    "bitmap = digit.reshape(13,8)\n",
    "\n",
    "# Print bitmap\n",
    "print(bitmap)\n",
    "\n",
    "# Use plt.imshow to display bitmap\n",
    "plt.imshow(bitmap, cmap='gray', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5adee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMF learns the parts of images\n",
    "def show_as_image(sample):\n",
    "    bitmap = sample.reshape((13, 8))\n",
    "    plt.figure()\n",
    "    plt.imshow(bitmap, cmap='gray', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# Create an NMF model: model\n",
    "model = NMF(n_components=7)\n",
    "\n",
    "# Apply fit_transform to samples: features\n",
    "features = model.fit_transform(lcd_df_samples)\n",
    "\n",
    "# Call show_as_image on each component\n",
    "for component in model.components_:\n",
    "    show_as_image(component)\n",
    "\n",
    "# Assign the 0th row of features: digit_features\n",
    "digit_features = features[0,:]\n",
    "\n",
    "# Print digit_features\n",
    "print(digit_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA doesn't learn parts\n",
    "\n",
    "# Create a PCA instance: model\n",
    "model = PCA(n_components=7)\n",
    "\n",
    "# Apply fit_transform to samples: features\n",
    "features = model.fit_transform(lcd_df_samples)\n",
    "\n",
    "# Call show_as_image on each component\n",
    "for component in model.components_:\n",
    "    show_as_image(component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae598a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Recommend musical artists part 1\n",
    "# artists_names_df = pd.read_csv('Dados/Musical artists/artists.csv', sep=',', header = None)\n",
    "# artists_df = pd.read_csv('Dados/Musical artists/scrobbler-small-sample.csv', sep=',')\n",
    "\n",
    "# # Create a MaxAbsScaler: scaler\n",
    "# scaler = MaxAbsScaler()\n",
    "\n",
    "# # Create an NMF model: nmf\n",
    "# nmf = NMF(n_components=20)\n",
    "\n",
    "# # Create a Normalizer: normalizer\n",
    "# normalizer = Normalizer()\n",
    "\n",
    "# # Create a pipeline: pipeline\n",
    "# pipeline = make_pipeline(scaler,nmf,normalizer)\n",
    "\n",
    "# # Apply fit_transform to artists: norm_features\n",
    "# norm_features = pipeline.fit_transform(artists_df)\n",
    "\n",
    "\n",
    "# #Recommend musical artists part 2\n",
    "\n",
    "# # Create a DataFrame: df\n",
    "# df = pd.DataFrame(norm_features, index=artists_names_df[:])\n",
    "\n",
    "# # Select row of 'Bruce Springsteen': artist\n",
    "# artist = df.loc['Bruce Springsteen']\n",
    "\n",
    "# # Compute cosine similarities: similarities\n",
    "# similarities = df.dot(artist)\n",
    "\n",
    "# # Display those with highest cosine similarity\n",
    "# print(similarities.nlargest())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
